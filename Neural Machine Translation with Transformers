{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9963326,"sourceType":"datasetVersion","datasetId":6128736}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from nltk.tokenize import WordPunctTokenizer\nfrom subword_nmt.learn_bpe import learn_bpe\nfrom subword_nmt.apply_bpe import BPE\nimport ast\nimport numpy as np\n\ntokenizer = WordPunctTokenizer()\n\ndef tokenize(x):\n    return ' '.join(tokenizer.tokenize(x.lower()))\n\n\ntrain = []\nwith open('/kaggle/input/data-transl/train', 'r') as f, open('train.alien', 'w') as f_src, open('train.en', 'w') as f_dst:\n    for line in f:\n        train.append(ast.literal_eval(line.strip()))\n        f_src.write(tokenize(train[-1]['src']) + '\\n')\n        f_dst.write(tokenize(train[-1]['dst']) + '\\n')\n\n\nbpe = {}\nfor lang in ['alien', 'en']:\n    learn_bpe(open(f'./train.{lang}'), open(f'bpe_rules.{lang}', 'w'), num_symbols=8000)\n    bpe[lang] = BPE(open(f'./bpe_rules.{lang}'))\n\n    \n    with open(f'train.bpe.{lang}', 'w') as f_out:\n        for line in open(f'./train.{lang}'):\n            f_out.write(bpe[lang].process_line(line.strip()) + '\\n')\n\n\nval = []\nwith open('/kaggle/input/data-transl/val', 'r') as v, open('val.alien', 'w') as v_src, open('val.en', 'w') as v_dst:\n    for line in v:\n        val.append(ast.literal_eval(line.strip()))\n        v_src.write(tokenize(val[-1]['src']) + '\\n')\n        v_dst.write(tokenize(val[-1]['dst']) + '\\n')\n\nfor lang in ['alien', 'en']:\n    with open(f'val.bpe.{lang}', 'w') as v_out:\n        for line in open(f'./val.{lang}'):\n            v_out.write(bpe[lang].process_line(line.strip()) + '\\n')\n\ndata_inp = np.array(open('./train.bpe.alien').read().split('\\n'))\ndata_out = np.array(open('./train.bpe.en').read().split('\\n'))\ntrain_out = data_out\ntrain_inp = data_inp\n\ndatav_inp = np.array(open('./val.bpe.alien').read().split('\\n'))\ndatav_out = np.array(open('./val.bpe.en').read().split('\\n'))\ndev_out = datav_out\ndev_inp = datav_inp\n\nfor i in range(2):\n    print('inp:', train_inp[i])\n    print('out:', train_out[i], end='\\n\\n')\n\nfor i in range(2):\n    print('inp:', dev_inp[i])\n    print('out:', dev_out[i], end='\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T19:05:42.620085Z","iopub.execute_input":"2025-01-22T19:05:42.620876Z","iopub.status.idle":"2025-01-22T19:07:23.554570Z","shell.execute_reply.started":"2025-01-22T19:05:42.620841Z","shell.execute_reply":"2025-01-22T19:07:23.553652Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 8000/8000 [00:56<00:00, 140.98it/s]\n100%|██████████| 8000/8000 [00:09<00:00, 862.61it/s] \n","output_type":"stream"},{"name":"stdout","text":"inp: ◄▴◓@@ ◠▨ ◨@@ ▽◠▦@@ ◈◬◓▪@@ ▼◬▵\nout: - intri@@ gu@@ ing .\n\ninp: ▽◪@@ ◎◗▦@@ ◫▦◫ ▫▴▨◓◠◓ ▴▫◎◪@@ ▱◫ ◚▴ ◞◧▦@@ ◞▾▢@@ ▱◨▨ ◒◠◓◠@@ ◀@@ ▪▦◈◠▦ ◫◉@@ ◎▴@@ ▱◫▵\nout: he would need to repeat his vo@@ ws in the land of the living and drink from the wine of ages .\n\ninp: ◘@@ ◚ ◞◠▷◫@@ ◀◗ ▫◠▨◬@@ ◎ ▨◪▦◈@@ ◫▦◫ ▫◧▻▱◠@@ ◈▪ ◚◪ ◝◂@@ ▾▼@@ ▷◠◓@@ ◈@@ '◬▦ 2@@ 7 : 3@@ 7 '@@ ◈▴▨◗ ◕@@ ◂▱@@ ◭ ◀◗◓ ▨▴▢ ◈◠▷◠ ◞@@ ▨◂◓@@ ◨ ▴@@ ◒◗@@ ▫@@ ▱◪@@ ◈◗▵\nout: the ho@@ sts re@@ grou@@ ped , and bou@@ chard ev@@ ened the score again , scor@@ ing a goal with a 27 - 37 man advantage .\n\ninp: ◤@@ ◪▦◫ ▨◠▦@@ ◞▴◓ ◠◒▪@@ ◞▪■ ◀◠◐▪@@ ◒◬@@ ▨@@ ▱▪▨ ◞@@ ◫◞▫@@ ◪◎@@ ◫▦▴ ▨◣▫◭ ▦@@ ◫◳@@ ◪▫@@ ▱◗ ▷@@ ▩▼@@ ◓◪@@ ▱▴◓◫ \"@@ ◕◣◓@@ ◎▴▽@@ ◫@@ \" ◇◐◓@@ ◪▫▴@@ ◀◫▱◗◓\nout: a new cancer vac@@ cine may teach the immune system to \" see \" ab@@ normal cells\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T19:10:56.171252Z","iopub.execute_input":"2025-01-22T19:10:56.172095Z","iopub.status.idle":"2025-01-22T19:10:56.177109Z","shell.execute_reply.started":"2025-01-22T19:10:56.172061Z","shell.execute_reply":"2025-01-22T19:10:56.176127Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import sys\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\n\nclass Vocab:\n    def __init__(self, tokens, bos=\"_BOS_\", eos=\"_EOS_\", unk='_UNK_', pad='_PAD_'):\n        assert all(tok in tokens for tok in (bos, eos, unk, pad))\n        self.tokens = tokens\n        self.token_to_ix = {t: i for i, t in enumerate(tokens)}\n        self.bos, self.eos, self.unk, self.pad = bos, eos, unk, pad\n        self.bos_ix = self.token_to_ix[bos]\n        self.eos_ix = self.token_to_ix[eos]\n        self.unk_ix = self.token_to_ix[unk]\n        self.pad_ix = self.token_to_ix[pad]\n\n    def __len__(self):\n        return len(self.tokens)\n\n    @staticmethod\n    def from_lines(lines, bos=\"_BOS_\", eos=\"_EOS_\", unk='_UNK_', pad='_PAD_'):\n        flat_lines = '\\n'.join(list(lines)).split()\n        tokens = sorted(set(flat_lines))\n        tokens = [t for t in tokens if t not in (bos, eos, unk, pad) and len(t)]\n        tokens = [bos, eos, unk, pad] + tokens\n        return Vocab(tokens, bos, eos, unk, pad)\n\n    def tokenize(self, string):\n        if not string.strip():\n            return [self.bos, self.eos]\n        tokens = [tok if tok in self.token_to_ix else self.unk\n                  for tok in string.split()]\n        return [self.bos] + tokens + [self.eos]\n\n    def to_matrix(self, lines, dtype=torch.int64, max_len=None):\n        lines = list(map(self.tokenize, lines))\n        if not lines:\n            return torch.empty((0, 0), dtype=dtype)\n        max_len = max_len or max(map(len, lines))\n\n        matrix = torch.full((len(lines), max_len), self.pad_ix, dtype=dtype)\n        for i, seq in enumerate(lines):\n            row_ix = list(map(self.token_to_ix.get, seq))[:max_len]\n            matrix[i, :len(row_ix)] = torch.as_tensor(row_ix)\n        return matrix\n\n    def to_lines(self, matrix, crop=True):\n        if matrix.numel() == 0:\n            return []\n        lines = []\n        for line_ix in map(list, matrix):\n            if crop:\n                if line_ix[0] == self.bos_ix:\n                    line_ix = line_ix[1:]\n                if self.eos_ix in line_ix:\n                    line_ix = line_ix[:line_ix.index(self.eos_ix)]\n            line = ' '.join(self.tokens[i] for i in line_ix if i != self.pad_ix)\n            lines.append(line)\n        return lines\n\n    def compute_mask(self, input_ix):\n        return F.pad(torch.cumsum(input_ix == self.eos_ix, dim=-1)[..., :-1] < 1, pad=(1, 0, 0, 0), value=True)\n\n    def get_pad_index(self):\n        return self.pad_ix\n\n    def get_bos_index(self):\n        return self.bos_ix\n\n    def get_eos_index(self):\n        return self.eos_ix\n\n    def to_string(self, indices):\n        \"\"\"\n        Преобразует последовательность индексов в строку токенов.\n        \"\"\"\n        return ' '.join(self.tokens[idx] for idx in indices if idx != self.pad_ix)\n\n\n\ninp_voc = Vocab.from_lines(train_inp)\nout_voc = Vocab.from_lines(train_out)\n#out_voc.get_pad_index('<pad>')\ntgt_pad_index = out_voc.get_pad_index()\n\nimport pickle\n\nwith open('inp_voc.pkl', 'wb') as f:\n    pickle.dump(inp_voc, f)\n\nwith open('out_voc.pkl', 'wb') as f:\n    pickle.dump(out_voc, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T19:10:59.566850Z","iopub.execute_input":"2025-01-22T19:10:59.567204Z","iopub.status.idle":"2025-01-22T19:11:04.478749Z","shell.execute_reply.started":"2025-01-22T19:10:59.567174Z","shell.execute_reply":"2025-01-22T19:11:04.477793Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Neural Machine Translation with Transformers\r\n\r\n","metadata":{}},{"cell_type":"code","source":"import math\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\nclass MultiHeadAttention(d2l.Module): \n    def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):\n        super().__init__()\n        self.num_heads = num_heads\n        self.attention = d2l.DotProductAttention(dropout)\n        self.W_q = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_k = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_v = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_o = nn.LazyLinear(num_hiddens, bias=bias)\n\n    def forward(self, queries, keys, values, valid_lens):\n        queries = self.transpose_qkv(self.W_q(queries))\n        keys = self.transpose_qkv(self.W_k(keys))\n        values = self.transpose_qkv(self.W_v(values))\n\n        if valid_lens is not None:\n            valid_lens = torch.repeat_interleave(\n                valid_lens, repeats=self.num_heads, dim=0)\n\n        output = self.attention(queries, keys, values, valid_lens)\n        output_concat = self.transpose_output(output)\n        return self.W_o(output_concat)\n@d2l.add_to_class(MultiHeadAttention)  #save\ndef transpose_qkv(self, X):\n    X = X.reshape(X.shape[0], X.shape[1], self.num_heads, -1)\n    X = X.permute(0, 2, 1, 3)\n    return X.reshape(-1, X.shape[2], X.shape[3])\n\n@d2l.add_to_class(MultiHeadAttention)\ndef transpose_output(self, X):\n    X = X.reshape(-1, self.num_heads, X.shape[1], X.shape[2])\n    X = X.permute(0, 2, 1, 3)\n    return X.reshape(X.shape[0], X.shape[1], -1)\nclass PositionalEncoding(nn.Module):\n    def __init__(self, num_hiddens, dropout, max_len=1000):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.P = torch.zeros((1, max_len, num_hiddens))\n        X = torch.arange(max_len, dtype=torch.float32).reshape(\n            -1, 1) / torch.pow(10000, torch.arange(\n            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n        self.P[:, :, 0::2] = torch.sin(X)\n        self.P[:, :, 1::2] = torch.cos(X)\n\n    def forward(self, X):\n        X = X + self.P[:, :X.shape[1], :].to(X.device)\n        return self.dropout(X)\nclass PositionWiseFFN(nn.Module):\n    def __init__(self, ffn_num_hiddens, ffn_num_outputs):\n        super().__init__()\n        self.dense1 = nn.LazyLinear(ffn_num_hiddens)\n        self.relu = nn.ReLU()\n        self.dense2 = nn.LazyLinear(ffn_num_outputs)\n\n    def forward(self, X):\n        return self.dense2(self.relu(self.dense1(X)))\n\nclass AddNorm(nn.Module): \n    def __init__(self, norm_shape, dropout):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.ln = nn.LayerNorm(norm_shape)\n\n    def forward(self, X, Y):\n        return self.ln(self.dropout(Y) + X)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T19:11:14.625659Z","iopub.execute_input":"2025-01-22T19:11:14.626722Z","iopub.status.idle":"2025-01-22T19:11:16.255661Z","shell.execute_reply.started":"2025-01-22T19:11:14.626673Z","shell.execute_reply":"2025-01-22T19:11:16.254705Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Encoder","metadata":{}},{"cell_type":"code","source":"class TransformerEncoderBlock(nn.Module):  #\n    \n    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,\n                 use_bias=False):\n        super().__init__()\n        self.attention = d2l.MultiHeadAttention(num_hiddens, num_heads,\n                                                dropout, use_bias)\n        self.addnorm1 = AddNorm(num_hiddens, dropout)\n        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n        self.addnorm2 = AddNorm(num_hiddens, dropout)\n\n    def forward(self, X, valid_lens):\n        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n        return self.addnorm2(Y, self.ffn(Y))\n\nclass TransformerEncoder(d2l.Encoder):  #\n    \n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,\n                 num_heads, num_blks, dropout, use_bias=False):\n        super().__init__()\n        self.num_hiddens = num_hiddens\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_blks):\n            self.blks.add_module(\"block\"+str(i), TransformerEncoderBlock(\n                num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias))\n\n    def forward(self, X, valid_lens):\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self.attention_weights = [None] * len(self.blks)\n        for i, blk in enumerate(self.blks):\n            X = blk(X, valid_lens)\n            self.attention_weights[\n                i] = blk.attention.attention.attention_weights\n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T19:11:21.312558Z","iopub.execute_input":"2025-01-22T19:11:21.313415Z","iopub.status.idle":"2025-01-22T19:11:21.321614Z","shell.execute_reply.started":"2025-01-22T19:11:21.313378Z","shell.execute_reply":"2025-01-22T19:11:21.320700Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Decoder","metadata":{}},{"cell_type":"code","source":"class TransformerDecoderBlock(nn.Module):\n    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout, i):\n        super().__init__()\n        self.i = i\n        self.attention1 = d2l.MultiHeadAttention(num_hiddens, num_heads,\n                                                 dropout)\n        self.addnorm1 = AddNorm(num_hiddens, dropout)\n        self.attention2 = d2l.MultiHeadAttention(num_hiddens, num_heads,\n                                                 dropout)\n        self.addnorm2 = AddNorm(num_hiddens, dropout)\n        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n        self.addnorm3 = AddNorm(num_hiddens, dropout)\n\n    def forward(self, X, state):\n        enc_outputs, enc_valid_lens = state[0], state[1]\n        if state[2][self.i] is None:\n            key_values = X\n        else:\n            key_values = torch.cat((state[2][self.i], X), dim=1)\n        state[2][self.i] = key_values\n        if self.training:\n            batch_size, num_steps, _ = X.shape\n            \n            dec_valid_lens = torch.arange(\n                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n        else:\n            dec_valid_lens = None\n        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n        Y = self.addnorm1(X, X2)\n        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n        Z = self.addnorm2(Y, Y2)\n        return self.addnorm3(Z, self.ffn(Z)), state\n\nclass TransformerDecoder(d2l.AttentionDecoder):\n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n                 num_blks, dropout):\n        super().__init__()\n        self.num_hiddens = num_hiddens\n        self.num_blks = num_blks\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_blks):\n            self.blks.add_module(\"block\"+str(i), TransformerDecoderBlock(\n                num_hiddens, ffn_num_hiddens, num_heads, dropout, i))\n        self.dense = nn.LazyLinear(vocab_size)\n\n    def init_state(self, enc_outputs, enc_valid_lens):\n        return [enc_outputs, enc_valid_lens, [None] * self.num_blks]\n\n    def forward(self, X, state):\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n        for i, blk in enumerate(self.blks):\n            X, state = blk(X, state)\n            self._attention_weights[0][\n                i] = blk.attention1.attention.attention_weights\n            self._attention_weights[1][\n                i] = blk.attention2.attention.attention_weights\n        return self.dense(X), state\n\n    @property\n    def attention_weights(self):\n        return self._attention_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T19:11:28.051284Z","iopub.execute_input":"2025-01-22T19:11:28.052069Z","iopub.status.idle":"2025-01-22T19:11:28.064316Z","shell.execute_reply.started":"2025-01-22T19:11:28.052035Z","shell.execute_reply":"2025-01-22T19:11:28.063132Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_inp_tensor = inp_voc.to_matrix(train_inp).to(device)\ntrain_out_tensor = out_voc.to_matrix(train_out).to(device)\n\ndev_inp_tensor = inp_voc.to_matrix(dev_inp).to(device)\ndev_out_tensor = out_voc.to_matrix(dev_out).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T19:11:32.870460Z","iopub.execute_input":"2025-01-22T19:11:32.870915Z","iopub.status.idle":"2025-01-22T19:11:48.153821Z","shell.execute_reply.started":"2025-01-22T19:11:32.870869Z","shell.execute_reply":"2025-01-22T19:11:48.153014Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\nfrom torch.utils.data import DataLoader, TensorDataset\ntrain_dataset = TensorDataset(train_inp_tensor, train_out_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\ndev_dataset = TensorDataset(dev_inp_tensor, dev_out_tensor)\ndev_loader = DataLoader(dev_dataset, batch_size=16, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T19:11:51.903530Z","iopub.execute_input":"2025-01-22T19:11:51.903895Z","iopub.status.idle":"2025-01-22T19:11:51.910414Z","shell.execute_reply.started":"2025-01-22T19:11:51.903865Z","shell.execute_reply":"2025-01-22T19:11:51.909538Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nclass TransformerModel(nn.Module):\n    def __init__(self, inp_voc, out_voc, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout):\n        super(TransformerModel, self).__init__()\n        self.encoder = TransformerEncoder(len(inp_voc), num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout)\n        self.decoder = TransformerDecoder(len(out_voc), num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout)\n        self.out_voc = out_voc\n\n    def forward(self, inp, out):\n        enc_outputs = self.encoder(inp, None)\n        dec_state = self.decoder.init_state(enc_outputs, None)\n        return self.decoder(out, dec_state)\n\n\n#num_hiddens = 512\n#ffn_num_hiddens = 2048\n#num_heads = 8\n#num_blks = 6\ntorch.cuda.empty_cache()\nnum_blks = 4\nnum_heads = 4\nnum_hiddens = 256\nffn_num_hiddens = 1024\n\ndropout = 0.1\n\n\nmodel = TransformerModel(inp_voc, out_voc, num_hiddens, ffn_num_hiddens, num_heads, num_blks, dropout).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=out_voc.get_pad_index())\noptimizer = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T20:36:20.737568Z","iopub.execute_input":"2025-01-22T20:36:20.738371Z","iopub.status.idle":"2025-01-22T20:36:20.815421Z","shell.execute_reply.started":"2025-01-22T20:36:20.738338Z","shell.execute_reply":"2025-01-22T20:36:20.814644Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\ndef train(model, train_loader, criterion, optimizer, num_epochs=10):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        for inp, out in train_loader:\n            inp.to(device), out.to(device)\n            optimizer.zero_grad()\n            out_pred, _ = model(inp, out[:, :-1])\n            loss = criterion(out_pred.permute(0, 2, 1), out[:, 1:])\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')\n        \n        \n        torch.save(model.state_dict(), f'../working/model_epoch_{epoch+1}.pth')\n        torch.cuda.empty_cache()\n\n\ndef validate(model, dev_loader, criterion):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for inp, out in dev_loader:\n            inp, out = inp.to(device), out.to(device)\n            out_pred, _ = model(inp, out[:, :-1])\n            loss = criterion(out_pred.permute(0, 2, 1), out[:, 1:])\n            total_loss += loss.item()\n    print(f'Validation Loss: {total_loss/len(dev_loader)}')\n\n\ntorch.cuda.empty_cache()\ntrain(model, train_loader, criterion, optimizer, num_epochs=10)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T20:36:25.737045Z","iopub.execute_input":"2025-01-22T20:36:25.737360Z","iopub.status.idle":"2025-01-22T23:18:31.488915Z","shell.execute_reply.started":"2025-01-22T20:36:25.737334Z","shell.execute_reply":"2025-01-22T23:18:31.487974Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 4.22470003179878\nEpoch 2, Loss: 3.6913880393013154\nEpoch 3, Loss: 3.4349060890852727\nEpoch 4, Loss: 3.26138519123137\nEpoch 5, Loss: 3.1266665501719406\nEpoch 6, Loss: 3.01427622593776\nEpoch 7, Loss: 2.919137865376469\nEpoch 8, Loss: 2.8355444994209784\nEpoch 9, Loss: 2.76395321649511\nEpoch 10, Loss: 2.7030348901869194\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"validate(model, dev_loader, criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T23:18:31.490404Z","iopub.execute_input":"2025-01-22T23:18:31.490686Z","iopub.status.idle":"2025-01-22T23:18:32.226714Z","shell.execute_reply.started":"2025-01-22T23:18:31.490659Z","shell.execute_reply":"2025-01-22T23:18:32.225879Z"}},"outputs":[{"name":"stdout","text":"Validation Loss: 5.787325635552406\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"test = []\nwith open('/kaggle/input/data-transl/test_no_reference', 'r') as f, open('test.alien', 'w') as test_src:\n    for line in f:\n        data = ast.literal_eval(line.strip())\n        test.append(data)\n        test_src.write(tokenize(data['src']) + '\\n')\n\nfor lang in ['alien']:\n    with open(f'test.bpe.{lang}', 'w') as test_out:\n        for line in open(f'test.{lang}'):\n            test_out.write(bpe[lang].process_line(line.strip()) + '\\n')\n\ntest_data_inp = np.array(open('./test.bpe.alien').read().split('\\n'))\ntest_inp = test_data_inp\n\ntest_inp_tensor = inp_voc.to_matrix(test_inp).to(device)\n\ntest_dataset = TensorDataset(test_inp_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T23:19:06.635475Z","iopub.execute_input":"2025-01-22T23:19:06.635828Z","iopub.status.idle":"2025-01-22T23:19:06.913617Z","shell.execute_reply.started":"2025-01-22T23:19:06.635796Z","shell.execute_reply":"2025-01-22T23:19:06.912865Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"test = []\nwith open('/kaggle/input/data-transl/test_no_reference', 'r') as f, open('test.alien', 'w') as test_src:\n    for line in f:\n        data = ast.literal_eval(line.strip())\n        test.append(data)\n        test_src.write(tokenize(data['src']) + '\\n')\n\nfor lang in ['alien']:\n    with open(f'test.bpe.{lang}', 'w') as test_out:\n        for line in open(f'test.{lang}'):\n            test_out.write(bpe[lang].process_line(line.strip()) + '\\n')\n\ntest_data_inp = np.array([line for line in open('./test.bpe.alien').read().split('\\n') if line.strip()])\ntest_inp = test_data_inp\n\ntest_inp_tensor = inp_voc.to_matrix(test_inp).to(device)\n\ntest_dataset = TensorDataset(test_inp_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T23:27:47.267667Z","iopub.execute_input":"2025-01-22T23:27:47.268561Z","iopub.status.idle":"2025-01-22T23:27:47.414204Z","shell.execute_reply.started":"2025-01-22T23:27:47.268527Z","shell.execute_reply":"2025-01-22T23:27:47.413442Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"len(test_inp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T23:27:51.746504Z","iopub.execute_input":"2025-01-22T23:27:51.746872Z","iopub.status.idle":"2025-01-22T23:27:51.752463Z","shell.execute_reply.started":"2025-01-22T23:27:51.746841Z","shell.execute_reply":"2025-01-22T23:27:51.751604Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def to_string(self, indices):\n    \"\"\"\n    Преобразует последовательность индексов в строку токенов.\n    \"\"\"\n    valid_indices = [idx for idx in indices if idx < len(self.tokens) and idx != self.pad_ix]\n    return ' '.join(self.tokens[idx] for idx in valid_indices)\n\n\ndef generate_predictions(model, test_dataset, inp_voc, out_voc, max_len=100):\n    model.eval()\n    predictions = []\n    BOS_IDX = out_voc.get_bos_index()  # Индекс токена начала последовательности\n    EOS_IDX = out_voc.get_eos_index()  # Индекс токена конца последовательности\n\n    with torch.no_grad():\n        for inp in test_dataset:\n            inp = inp[0].unsqueeze(0).to(device)\n            enc_outputs = model.encoder(inp, None)\n            dec_state = model.decoder.init_state(enc_outputs, None)\n            dec_input = torch.tensor([[BOS_IDX]], device=device)\n            output_seq = []\n            for _ in range(max_len):\n                out_pred, dec_state = model.decoder(dec_input, dec_state)\n                dec_input = out_pred.argmax(dim=2)\n                next_token = dec_input.squeeze().item()\n                if next_token == EOS_IDX:\n                    break\n                output_seq.append(next_token)\n            \n            \n            predictions.append(out_voc.to_string(output_seq))  # Используем to_string\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T23:27:58.410312Z","iopub.execute_input":"2025-01-22T23:27:58.410892Z","iopub.status.idle":"2025-01-22T23:27:58.418137Z","shell.execute_reply.started":"2025-01-22T23:27:58.410858Z","shell.execute_reply":"2025-01-22T23:27:58.417245Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import json \npredictions = generate_predictions(model, test_dataset, inp_voc, out_voc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T23:28:02.397798Z","iopub.execute_input":"2025-01-22T23:28:02.398123Z","iopub.status.idle":"2025-01-22T23:31:16.226400Z","shell.execute_reply.started":"2025-01-22T23:28:02.398097Z","shell.execute_reply":"2025-01-22T23:31:16.225687Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"print(f\"Number of predictions: {len(predictions)}\")\nprint(f\"Number of test items: {len(test)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T23:32:03.225129Z","iopub.execute_input":"2025-01-22T23:32:03.225827Z","iopub.status.idle":"2025-01-22T23:32:03.230517Z","shell.execute_reply.started":"2025-01-22T23:32:03.225790Z","shell.execute_reply":"2025-01-22T23:32:03.229355Z"}},"outputs":[{"name":"stdout","text":"Number of predictions: 1000\nNumber of test items: 1000\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"with open('predictions.jsonl', 'w') as f:\n    for i, pred in enumerate(predictions[:-1]):\n        json_line = json.dumps({\"dst\": pred, \"src\": test[i]['src']}, ensure_ascii=False)\n        f.write(json_line + '\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T23:32:07.253252Z","iopub.execute_input":"2025-01-22T23:32:07.254193Z","iopub.status.idle":"2025-01-22T23:32:07.268676Z","shell.execute_reply.started":"2025-01-22T23:32:07.254156Z","shell.execute_reply":"2025-01-22T23:32:07.268075Z"}},"outputs":[],"execution_count":33}]}